{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"ASL_Aspire_Mediapipe.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1wUto4Bvi_IYRPQ4Ph0jgNtkjKJaPdzr_\n",
        "\n",
        "Usage example of MediaPipe Hands Solution API in Python (see also http://solutions.mediapipe.dev/hands).\n",
        "\"\"\"\n",
        "\n",
        "#**\n",
        "\n",
        "\n",
        "#**\n",
        "!pip install mediapipe\n",
        "!pip install keras\n"
      ],
      "metadata": {
        "id": "0Utx0M3EOszg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import extract_features\n",
        "# Import the much needed stuff for training\n",
        "import keras\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import mediapipe as mp\n",
        "import os\n",
        "import csv\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras\n",
        "# Make numpy values easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "WGJMe-BxPZCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"data_archive.zip\", 'r') as zObject:\n",
        "\n",
        "    # Extracting all the members of the zip\n",
        "    # into a specific location.\n",
        "    zObject.extractall(\n",
        "        path=\"data_archive\")\n"
      ],
      "metadata": {
        "id": "bVCdbvJOPgzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Checking Tensorflow Version\n",
        "\n",
        "\"\"\"#Extract Features Function:\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"#CSV Data Storage Function:\n",
        "Create CSV\n",
        "\"\"\"\n",
        "\n",
        "#Function to create CSV file or add dataset to the existed CSV file\n",
        "def toCSV(filecsv, class_type,\n",
        "          wristX, wristY, wristZ,\n",
        "          thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n",
        "          thumb_McpX, thumb_McpY, thumb_McpZ,\n",
        "          thumb_IpX, thumb_IpY, thumb_IpZ,\n",
        "          thumb_TipX, thumb_TipY, thumb_TipZ,\n",
        "          index_McpX, index_McpY, index_McpZ,\n",
        "          index_PipX, index_PipY, index_PipZ,\n",
        "          index_DipX, index_DipY, index_DipZ,\n",
        "          index_TipX, index_TipY, index_TipZ,\n",
        "          middle_McpX, middle_McpY, middle_McpZ,\n",
        "          middle_PipX, middle_PipY, middle_PipZ,\n",
        "          middle_DipX, middle_DipY, middle_DipZ,\n",
        "          middle_TipX, middle_TipY, middle_TipZ,\n",
        "          ring_McpX, ring_McpY, ring_McpZ,\n",
        "          ring_PipX, ring_PipY, ring_PipZ,\n",
        "          ring_DipX, ring_DipY, ring_DipZ,\n",
        "          ring_TipX, ring_TipY, ring_TipZ,\n",
        "          pinky_McpX, pinky_McpY, pinky_McpZ,\n",
        "          pinky_PipX, pinky_PipY, pinky_PipZ,\n",
        "          pinky_DipX, pinky_DipY, pinky_DipZ,\n",
        "          pinky_TipX, pinky_TipY, pinky_TipZ):\n",
        "    if os.path.isfile(filecsv):\n",
        "        #print (\"File exist thus shall write append to the file\")\n",
        "        with open(filecsv, 'a+', newline='') as file:\n",
        "            # Create a writer object from csv module\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([class_type,\n",
        "                             wristX, wristY, wristZ,\n",
        "                             thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n",
        "                             thumb_McpX, thumb_McpY, thumb_McpZ,\n",
        "                             thumb_IpX, thumb_IpY, thumb_IpZ,\n",
        "                             thumb_TipX, thumb_TipY, thumb_TipZ,\n",
        "                             index_McpX, index_McpY, index_McpZ,\n",
        "                             index_PipX, index_PipY, index_PipZ,\n",
        "                             index_DipX, index_DipY, index_DipZ,\n",
        "                             index_TipX, index_TipY, index_TipZ,\n",
        "                             middle_McpX, middle_McpY, middle_McpZ,\n",
        "                             middle_PipX, middle_PipY, middle_PipZ,\n",
        "                             middle_DipX, middle_DipY, middle_DipZ,\n",
        "                             middle_TipX, middle_TipY, middle_TipZ,\n",
        "                             ring_McpX, ring_McpY, ring_McpZ,\n",
        "                             ring_PipX, ring_PipY, ring_PipZ,\n",
        "                             ring_DipX, ring_DipY, ring_DipZ,\n",
        "                             ring_TipX, ring_TipY, ring_TipZ,\n",
        "                             pinky_McpX, pinky_McpY, pinky_McpZ,\n",
        "                             pinky_PipX, pinky_PipY, pinky_PipZ,\n",
        "                             pinky_DipX, pinky_DipY, pinky_DipZ,\n",
        "                             pinky_TipX, pinky_TipY, pinky_TipZ])\n",
        "    else:\n",
        "        #print (\"File not exist thus shall create new file as\", filecsv)\n",
        "        with open(filecsv, 'w', newline='') as file:\n",
        "            # Create a writer object from csv module\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"class_type\",\n",
        "                             \"wristX\", \"wristY\", \"wristZ\",\n",
        "                             \"thumb_CmcX\", \"thumb_CmcY\", \"thumb_CmcZ\",\n",
        "                             \"thumb_McpX\", \"thumb_McpY\", \"thumb_McpZ\",\n",
        "                             \"thumb_IpX\", \"thumb_IpY\", \"thumb_IpZ\",\n",
        "                             \"thumb_TipX\", \"thumb_TipY\", \"thumb_TipZ\",\n",
        "                             \"index_McpX\", \"index_McpY\", \"index_McpZ\",\n",
        "                             \"index_PipX\", \"index_PipY\", \"index_PipZ\",\n",
        "                             \"index_DipX\", \"index_DipY\", \"index_DipZ\",\n",
        "                             \"index_TipX\", \"index_TipY\", \"index_TipZ\",\n",
        "                             \"middle_McpX\", \"middle_McpY\", \"middle_McpZ\",\n",
        "                             \"middle_PipX\", \"middle_PipY\", \"middle_PipZ\",\n",
        "                             \"middle_DipX\", \"middle_DipY\", \"middle_DipZ\",\n",
        "                             \"middle_TipX\", \"middle_TipY\", \"middle_TipZ\",\n",
        "                             \"ring_McpX\", \"ring_McpY\", \"ring_McpZ\",\n",
        "                             \"ring_PipX\", \"ring_PipY\", \"ring_PipZ\",\n",
        "                             \"ring_DipX\", \"ring_DipY\", \"ring_DipZ\",\n",
        "                             \"ring_TipX\", \"ring_TipY\", \"ring_TipZ\",\n",
        "                             \"pinky_McpX\", \"pinky_McpY\", \"pinky_McpZ\",\n",
        "                             \"pinky_PipX\", \"pinky_PipY\", \"pinky_PipZ\",\n",
        "                             \"pinky_DipX\", \"pinky_DipY\", \"pinky_DipZ\",\n",
        "                             \"pinky_TipX\", \"pinky_TipY\", \"pinky_TipZ\"])\n",
        "            writer.writerow([class_type,\n",
        "                             wristX, wristY, wristZ,\n",
        "                             thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n",
        "                             thumb_McpX, thumb_McpY, thumb_McpZ,\n",
        "                             thumb_IpX, thumb_IpY, thumb_IpZ,\n",
        "                             thumb_TipX, thumb_TipY, thumb_TipZ,\n",
        "                             index_McpX, index_McpY, index_McpZ,\n",
        "                             index_PipX, index_PipY, index_PipZ,\n",
        "                             index_DipX, index_DipY, index_DipZ,\n",
        "                             index_TipX, index_TipY, index_TipZ,\n",
        "                             middle_McpX, middle_McpY, middle_McpZ,\n",
        "                             middle_PipX, middle_PipY, middle_PipZ,\n",
        "                             middle_DipX, middle_DipY, middle_DipZ,\n",
        "                             middle_TipX, middle_TipY, middle_TipZ,\n",
        "                             ring_McpX, ring_McpY, ring_McpZ,\n",
        "                             ring_PipX, ring_PipY, ring_PipZ,\n",
        "                             ring_DipX, ring_DipY, ring_DipZ,\n",
        "                             ring_TipX, ring_TipY, ring_TipZ,\n",
        "                             pinky_McpX, pinky_McpY, pinky_McpZ,\n",
        "                             pinky_PipX, pinky_PipY, pinky_PipZ,\n",
        "                             pinky_DipX, pinky_DipY, pinky_DipZ,\n",
        "                             pinky_TipX, pinky_TipY, pinky_TipZ])\n"
      ],
      "metadata": {
        "id": "2__PW3XuPzdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#Annotation of Data and Storage of Annotated Data:\"\"\"\n",
        "\n",
        "csv_path = \"data_archive/datafile.csv\"\n",
        "training_data_path = \"data_archive/asl_alphabet_train\"\n",
        "validation_data_path = \"data_archive/asl_alphabet_test\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    print(\"CSV Path exists!\")\n",
        "    \n",
        "for dirlist in os.listdir(training_data_path):\n",
        "    for root, directories, filenames in os.walk(os.path.join(training_data_path, dirlist)):\n",
        "        print(\"Inside Folder\", dirlist, \"Consist :\", len(filenames), \"Imageset\")\n",
        "        for filename in filenames:\n",
        "                print(root,filename)\n",
        "                print(os.path.join(root, filename), True)\n",
        "                (wristX, wristY, wristZ,\n",
        "                 thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n",
        "                 thumb_McpX, thumb_McpY, thumb_McpZ,\n",
        "                 thumb_IpX, thumb_IpY, thumb_IpZ,\n",
        "                 thumb_TipX, thumb_TipY, thumb_TipZ,\n",
        "                 index_McpX, index_McpY, index_McpZ,\n",
        "                 index_PipX, index_PipY, index_PipZ,\n",
        "                 index_DipX, index_DipY, index_DipZ,\n",
        "                 index_TipX, index_TipY, index_TipZ,\n",
        "                 middle_McpX, middle_McpY, middle_McpZ,\n",
        "                 middle_PipX, middle_PipY, middle_PipZ,\n",
        "                 middle_DipX, middle_DipY, middle_DipZ,\n",
        "                 middle_TipX, middle_TipY, middle_TipZ,\n",
        "                 ring_McpX, ring_McpY, ring_McpZ,\n",
        "                 ring_PipX, ring_PipY, ring_PipZ,\n",
        "                 ring_DipX, ring_DipY, ring_DipZ,\n",
        "                 ring_TipX, ring_TipY, ring_TipZ,\n",
        "                 pinky_McpX, pinky_McpY, pinky_McpZ,\n",
        "                 pinky_PipX, pinky_PipY, pinky_PipZ,\n",
        "                 pinky_DipX, pinky_DipY, pinky_DipZ,\n",
        "                 pinky_TipX, pinky_TipY, pinky_TipZ,\n",
        "                 annotated_image) = extract_features.extract_feature(os.path.join(root, filename))\n",
        "\n",
        "                if ((not wristX == 0) and (not wristY == 0)):\n",
        "                    toCSV(csv_path, dirlist, \n",
        "                          wristX, wristY, wristZ,\n",
        "                          thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n",
        "                          thumb_McpX, thumb_McpY, thumb_McpZ,\n",
        "                          thumb_IpX, thumb_IpY, thumb_IpZ,\n",
        "                          thumb_TipX, thumb_TipY, thumb_TipZ,\n",
        "                          index_McpX, index_McpY, index_McpZ,\n",
        "                          index_PipX, index_PipY, index_PipZ,\n",
        "                          index_DipX, index_DipY, index_DipZ,\n",
        "                          index_TipX, index_TipY, index_TipZ,\n",
        "                          middle_McpX, middle_McpY, middle_McpZ,\n",
        "                          middle_PipX, middle_PipY, middle_PipZ,\n",
        "                          middle_DipX, middle_DipY, middle_DipZ,\n",
        "                          middle_TipX, middle_TipY, middle_TipZ,\n",
        "                          ring_McpX, ring_McpY, ring_McpZ,\n",
        "                          ring_PipX, ring_PipY, ring_PipZ,\n",
        "                          ring_DipX, ring_DipY, ring_DipZ,\n",
        "                          ring_TipX, ring_TipY, ring_TipZ,\n",
        "                          pinky_McpX, pinky_McpY, pinky_McpZ,\n",
        "                          pinky_PipX, pinky_PipY, pinky_PipZ,\n",
        "                          pinky_DipX, pinky_DipY, pinky_DipZ,\n",
        "                          pinky_TipX, pinky_TipY, pinky_TipZ,)\n",
        "                \n",
        "                else :\n",
        "                    print(os.path.join(root, filename), \"Hand does not have landmarks\")\n",
        "\n",
        "print(\"===================Feature Extraction for TRAINING is Completed===================\")\n"
      ],
      "metadata": {
        "id": "jdHMw0yZQByh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract Feature for Validation\n",
        "# We will using SIBI datasets version V02\n",
        "\n",
        "csv_path2 = \"data_archive/valdatafile.csv\"\n",
        "\n",
        "for dirlist in os.listdir(validation_data_path):\n",
        "    for root, directories, filenames in os.walk(os.path.join(validation_data_path, dirlist)):\n",
        "        print(\"Inside Folder\", dirlist, \"Consist :\", len(filenames), \"Imageset\")\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n",
        "                #print(os.path.join(root, filename), True)\n",
        "                (wristX, wristY, wristZ,\n",
        "                 thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n",
        "                 thumb_McpX, thumb_McpY, thumb_McpZ,\n",
        "                 thumb_IpX, thumb_IpY, thumb_IpZ,\n",
        "                 thumb_TipX, thumb_TipY, thumb_TipZ,\n",
        "                 index_McpX, index_McpY, index_McpZ,\n",
        "                 index_PipX, index_PipY, index_PipZ,\n",
        "                 index_DipX, index_DipY, index_DipZ,\n",
        "                 index_TipX, index_TipY, index_TipZ,\n",
        "                 middle_McpX, middle_McpY, middle_McpZ,\n",
        "                 middle_PipX, middle_PipY, middle_PipZ,\n",
        "                 middle_DipX, middle_DipY, middle_DipZ,\n",
        "                 middle_TipX, middle_TipY, middle_TipZ,\n",
        "                 ring_McpX, ring_McpY, ring_McpZ,\n",
        "                 ring_PipX, ring_PipY, ring_PipZ,\n",
        "                 ring_DipX, ring_DipY, ring_DipZ,\n",
        "                 ring_TipX, ring_TipY, ring_TipZ,\n",
        "                 pinky_McpX, pinky_McpY, pinky_McpZ,\n",
        "                 pinky_PipX, pinky_PipY, pinky_PipZ,\n",
        "                 pinky_DipX, pinky_DipY, pinky_DipZ,\n",
        "                 pinky_TipX, pinky_TipY, pinky_TipZ,\n",
        "                 annotated_image) = extract_features.extract_feature(os.path.join(root, filename))\n",
        "            \n",
        "                if ((not wristX == 0) and (not wristY == 0)):\n",
        "                    toCSV(csv_path2, dirlist, \n",
        "                          wristX, wristY, wristZ,\n",
        "                          thumb_CmcX, thumb_CmcY, thumb_CmcZ,\n",
        "                          thumb_McpX, thumb_McpY, thumb_McpZ,\n",
        "                          thumb_IpX, thumb_IpY, thumb_IpZ,\n",
        "                          thumb_TipX, thumb_TipY, thumb_TipZ,\n",
        "                          index_McpX, index_McpY, index_McpZ,\n",
        "                          index_PipX, index_PipY, index_PipZ,\n",
        "                          index_DipX, index_DipY, index_DipZ,\n",
        "                          index_TipX, index_TipY, index_TipZ,\n",
        "                          middle_McpX, middle_McpY, middle_McpZ,\n",
        "                          middle_PipX, middle_PipY, middle_PipZ,\n",
        "                          middle_DipX, middle_DipY, middle_DipZ,\n",
        "                          middle_TipX, middle_TipY, middle_TipZ,\n",
        "                          ring_McpX, ring_McpY, ring_McpZ,\n",
        "                          ring_PipX, ring_PipY, ring_PipZ,\n",
        "                          ring_DipX, ring_DipY, ring_DipZ,\n",
        "                          ring_TipX, ring_TipY, ring_TipZ,\n",
        "                          pinky_McpX, pinky_McpY, pinky_McpZ,\n",
        "                          pinky_PipX, pinky_PipY, pinky_PipZ,\n",
        "                          pinky_DipX, pinky_DipY, pinky_DipZ,\n",
        "                          pinky_TipX, pinky_TipY, pinky_TipZ,)\n",
        "                \n",
        "                else :\n",
        "                    print(os.path.join(root, filename), \"Hand does not have landmarks\")\n",
        "                \n",
        "print(\"===================Feature Extraction for VALIDATION is Completed===================\")"
      ],
      "metadata": {
        "id": "DiUezYkXQGhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\"\"\"#Reading and Loading in the Extracted Data\n",
        "\n",
        "##Train Data Loading:\n",
        "\"\"\"\n",
        "\n",
        "# Read CSV file for Training the model using Pandas\n",
        "df_train = pd.read_csv(\"data_archive/datafile.csv\", header=0, error_bad_lines=False)\n",
        "\n",
        "\n",
        "# First we must sort the values of the dataset according to the Alphabets\n",
        "df_train = df_train.sort_values(by=[\"class_type\"]) #Every letter has a different class type. Sorts numerically.\n",
        "\n",
        "\n",
        "\"\"\"##Validation Data Loading:\"\"\"\n",
        "\n",
        "##**Run from this point onwards\n",
        "\n",
        "# Read CSV file for Validation or Testing the Model using Pandas\n",
        "df_val = pd.read_csv(\"data_archive/valdatafile.csv\", header=0,error_bad_lines=False)\n",
        "\n",
        "# First we must sort the values of the dataset according to the Alphabets\n",
        "df_val = df_val.sort_values(by=[\"class_type\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "-MfDYX5UQLXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\"\"\"##Data Configuration for Model Input\"\"\"\n",
        "\n",
        "# Put Categorical using Pandas\n",
        "#Categoricals can only take on only a limited, and usually fixed, number of possible values (categories)\n",
        "#All values of the Categorical are either in categories or np.nan\n",
        "df_train[\"class_type\"] = pd.Categorical(df_train[\"class_type\"]) #Creates a 'categorical' with the values being the inputed class_Type from above\n",
        "df_train[\"class_type\"] = df_train.class_type.cat.codes #Accesses the class type values, assigns a code to it\n",
        "#Later, this will correspond to the 0-26 A-Z letters\n",
        "\n",
        "df_val[\"class_type\"] = pd.Categorical(df_val[\"class_type\"])\n",
        "df_val[\"class_type\"] = df_val.class_type.cat.codes\n",
        "\n",
        "# Copy Label and Feature for training\n",
        "y_train = df_train.pop(\"class_type\") #Copies the df_val MINUS the class type indexes (i.e the landmarks)\n",
        "x_train = df_train.copy()\n",
        "\n",
        "y_val = df_val.pop(\"class_type\") #Same\n",
        "x_val = df_val.copy()\n",
        "\n",
        "# Copied Features turn to Array by using NumPy\n",
        "x_train = np.array(x_train)\n",
        "x_val = np.array(x_val)\n",
        "\n",
        "\n",
        "# Since the array shape is 1x10, we must turn it into 1x10x1 so we can feed it into the model\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
        "\n",
        "\n",
        "# Number of classes according standard American Language Alphabets\n",
        "num_classes = 24\n",
        "\n",
        "# Using the Keras.Utils to put the label categorically \n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val = to_categorical(y_val, num_classes)\n"
      ],
      "metadata": {
        "id": "G-10DQtLQPEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of available GPUs\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "numGpus = len(gpus)"
      ],
      "metadata": {
        "id": "B8FyCXdNIWJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAvRTYALOh0o"
      },
      "outputs": [],
      "source": [
        "\"\"\"#Model and Training:\"\"\"\n",
        "\n",
        "from keras.utils import multi_gpu_model\n",
        "\n",
        "# One Dimensional Convolutional Neural Network model, Train will be feed to 1 Dimension Convolutional Neural Network\n",
        "\n",
        "#TODO: Look into separable convolution\n",
        "#TODO: Try different variations of ELU\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=x_train.shape[1:3]),\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),  #added by Daniel\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),  #added by Daniel\n",
        "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),  #added by Daniel\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.Conv1D(filters=256, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),  ##added by Daniel\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Dropout(rate=0.25),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    tf.keras.layers.BatchNormalization(),  ##added by Daniel\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
        "\n",
        "parallel_model = multi_gpu_model(model, gpus=numGpus)\n",
        "\n",
        "parallel_model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#Setup for Tensorboard\n",
        "# %load_ext tensorboard\n",
        "\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for GPU availability\n",
        "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "#Train the Model on the CPU for comparison\n",
        "# startTime = time.time()\n",
        "# with tf.device('/CPU:0'):\n",
        "#   model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val),callbacks=[tensorboard_callback])\n",
        "# endTime = time.time()\n",
        "# print(\"Total Time Elapsed for CPU training:\" )\n",
        "# print(endTime - startTime)\n",
        "\n",
        "\n",
        "\n",
        "#Train the Model on the GPU\n",
        "#Steps for running on GPU: \n",
        "#1: Connect to Hosted Runtime from carrot on righthand side\n",
        "#2: Edit->Notebook Settings -> GPU\n",
        "\n",
        "startTime = time.time()\n",
        "parallel_model.fit(x_train, y_train, epochs=1500, batch_size=32, validation_data=(x_val, y_val),callbacks=[tensorboard_callback])\n",
        "endTime = time.time()\n",
        "print(\"Total Time Elapsed with GPU Acceleration:\" )\n",
        "print(endTime - startTime)\n",
        "\n",
        "%tensorboard --logdir logs/fit\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"##Saving Model\"\"\"\n",
        "\n",
        "#Saving the model into H5 system file\n",
        "save_model = \"full_data_set_model_ASL.h5\"\n",
        "model.save(save_model)\n",
        "print(\"Model Saved into\", save_model)\n"
      ],
      "metadata": {
        "id": "i93PRbfEITZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"##Saving Loss/Accuracy By Step\"\"\"\n",
        "\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "#saving the logs as CSV\n",
        "log_path = 'logs/fit/'\n",
        "event_acc = EventAccumulator(log_path)\n",
        "event_acc.Reload()\n",
        "\n",
        "\n",
        "loss_summary = event_acc.Scalars('loss')\n",
        "accuracy_summary = event_acc.Scalars('accuracy')\n",
        "\n",
        "# Convert the scalar summary data to a Pandas DataFrame\n",
        "loss_df = pd.DataFrame(loss_summary, columns=['step', 'loss'])\n",
        "accuracy_df = pd.DataFrame(accuracy_summary, columns=['step', 'accuracy'])\n",
        "\n",
        "# Write the data to a CSV file\n",
        "loss_df.to_csv('loss_summary.csv', index=False)\n",
        "accuracy_df.to_csv('accuracy_summary.csv', index=False)"
      ],
      "metadata": {
        "id": "H6BV9zFIJdQA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}